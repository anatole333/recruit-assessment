# 视觉设计方向考核任务
# 一、图像增强
## 1.1图像增强简介
	图像增强的首要目标是处理图像，使其比原始图像更加适合用于后续图像处理的应用。图像增强的方法是通过一定手段对原图像附加一些信息或变换数据，有选择地突出图像中感兴趣的特征或者抑制图像中某些不需要的特征，使图像与视觉响应特征想匹配。在图像增强过程中，不分析图像降质的原因，处理之后的图像不一定逼近原始图像，图像增强技术根据增强处理过程所在的空间不同，可以简单的分为基于空间域的算法和基于频域的算法。
	基于空间域的算不发处理直接对图像灰度级进行运算；基于频域的算法是在图像的某种变换域对图像的变换系数值进行某种修正，是一种间接增强的算法。
## 1.1空间域图像增强
### 1.1.1直方图均衡化算法原理
	直方图均衡化又称为直方图平坦化，实质上是对图像进行非线性拉伸，重新分配图像象元值，是一定灰度范围内象元值得数量大致相等。这样，原来直方图中间的峰顶部分对比度得到增强，而两侧的谷底部分对比度降低，输出图像的直方图是一个比较平的分段直方图：如果输出数据分段值较小的话，会产生粗略分类的视觉效果。
	直方图是表示数字图像中每一灰度出现频率的统计关系。直方图能给出图像灰度范围、每个灰度的频度和灰度的分布、整幅图像的平均明暗和对比度等概貌性描述。直灰度直方图是灰度级的函数，反应的是图像中具有该灰度级像素的个数，其横坐标是灰度级r，纵坐标是该灰度级出现的频率（即像素的个数），整个坐标系描述的是图像灰度级的分布。由此可以看出图像的灰度分布特性，即若大部分像素集中在低灰度区域，图像呈现暗的特性；若像素集中在高灰度区域，图像呈现亮的特性。
	假设r被归一化到区间[0，1]，且r=0表示黑色及r=1表示白色。然后，考虑一个离散公式并允许像素值在区间[0，L-1]内。对于任一个满足上述条件的r，本文将注意力集中在变换形式上：
s=T(r)  0≤r≤1
在原始图像中，对于每一个像素值r产生一个灰度值s。显然，可以假设变换函数T(r)满足以下条件：
	、T(r)在区间0≤r≤1中为单值且单调递增
	、当0≤r≤1时，0≤T(r)≤1
条件（1）中要求单值是为了保证反变换的存在，单调条件保持输出图像从黑到白顺序增加。如果变换函数不单调增加将导致至少有一部分亮度范围将被颠倒从 而导致在输出图像总产生反转灰度级。条件（2）保证输出灰度级与输入有同样的范围。
	一幅图像的灰度级可被视为去加[0,1]的随机变量。使用概率密度函数（PDF）对随机变量进行基本描述。描述如下所示：
	令P_r (r)和P_s (s)分别代表随机变量r和s的概率密度函数。如果P_r (r)和T(r)已知，且T^(-1) (s)满足条件(1),那么变量s的概率密度函数P_s (s)可以由下如下公司可以得到：
P_S (s)=P_r (r)|dr/ds|
### 1.1.2直方图均衡化算法实现
直方图均衡化算法分为四个步骤，
步骤一： 计算统计输入图像得直方图灰度级；
步骤二：累积归一化得直方图；
步骤三：计算直方图积分:H^' (i)=Sum(H(j))  (0≤j≤i)
步骤四：采用H^'作为查询表：dst(x,y)=H^' (src(x,y))对图像进行变换
	直方图均衡化算法主要使用C++的opencv库实现，创建灰度图像的直方图，计算图像的直方图灰度级，首先使用Histogram* CreateGrayImageHist(IplImage **ppImage)函数，创建灰度图像的直方图；然后使用IplImage* CreateHisogramImage(int nImageWidth, int nScale, int nImageHeight, CvHistogram *pcvHistogram)函数根据直方图创建直方图图像。	

## 1.2频率域图像增强
### 1.2.1频率域图像增强原理
	为了有效地对图像进行处理，常需要将原定义在图像空间的图像以某种形式转换到另外一些空间，并利用在这些空间的特有性质方便地进行一定的加工，最后再转换回图像空间以得到所需的效果。
	在做频率域图像增强之前首先需要将图像从空间域转换到频率域。对图像施行二维离散傅里叶变换或小波变换，将图像由图像空间转换到频域空间。
将图像折射到频率域之后，然后对频率域进行滤波，滤波将使用到平滑的频域滤波器以及锐化滤波器。平滑的频域滤波器包括低通滤波器、巴特沃斯低通滤波以及高斯低通滤波器。锐化滤波器中包括高通滤波器、巴特沃斯高通滤波以及高斯高通滤波器。
	最后使用傅里叶反变换，得到通过频率域图像增强的图像。
### 1.2.2频率域图像增强实现
（1）空间域转换到频域：使用傅里叶变换，将图像的信息从空间域转换到频域，使用傅里叶反变换可以实现从频域到空间域的无损转换，不丢失任何信息
>二维快速傅里叶变换
	clc;  %清空命令行  
	clear;%清空变量  
	   
	I1=imread('beauty.jpg');  
	subplot(1,2,1);  
	imshow(I1);  
	title('beauty.jpg');  
	   
	I2=fft2(I1);%计算二维FFT  
	spectrum =fftshift(I2);%将零点移到中心  
	temp= log(1+ abs(spectrum) ); %对幅值做 对数变换 以压缩动态范围  
	subplot(1,2,2);  
	imshow(temp,[]);  
	title('FFT');  
	   
	   
	I1=imread('line.bmp');  
	figure,  
	subplot(1,2,1);  
	imshow(I1);  
	title('line');  
	   
	I2=fft2(I1);%计算二维FFT  
	spectrum =fftshift(I2);%将零点移到中心  
	temp= log(1+ abs(spectrum) ); %对幅值做 对数变换 以压缩动态范围  
	subplot(1,2,2);  
	imshow(temp,[]);  
	title('FFT_line');  
（2）理想低通滤波
	 function ff=imidealflpf(I,freq)  
	   
	 [M,N]=size(I);  
	 ff=ones(M,N);  
	 for i=1:M  
	     for j=1:N  
	         if (sqrt ((i-M/2)^2+ (j-N/2)^2 ) >freq)  ff(i,j)=0; %高于截止频率 设为0  
	         end  
	     end  
	 end  
I：输入原图像freq：截止频率 最后将返回与I等大的频域滤镜
（3）高斯低通滤波
	   
	function ff=imgaussflpf(I,sigma)  
	[M,N]=size(I);  
	 ff=ones(M,N);  
	 for i=1:M  
	     for j=1:N  
	         ff(i,j)= exp( -((i-M/2)^2+(j-N/2)^2) /2/(sigma^2) ); %高斯函数  
	          
	     end  
	 end  
I：输入图像 sigma：标准差 最后将返回与原图像等大的高斯滤波滤镜
（4）高斯高通滤波器
	function ff=imgaussfhpf(I,sigma)  
	[M,N]=size(I);  
	 ff=ones(M,N);  
	 for i=1:M  
	     for j=1:N  
	         ff(i,j)= 1-exp( -((i-M/2)^2+(j-N/2)^2) /2/(sigma^2) ); %  1-(gauss)  
	          
	     end  
	 end  
I：输入图像 sigma：标准差 返回与原图等大的高斯高通滤镜
（5）拉普拉斯滤波器
	function ff=imlapf(I)  
	[M,N]=size(I);  
	 ff=ones(M,N);  
	 for i=1:M  
	     for j=1:N  
	         ff(i,j)= -((i-M/2)^2+(j-N/2)^2)  %   
	          
	     end  
	 end  
I：输入图像返回与原图等大的拉普拉斯高通滤镜

# 二、图像复原
## 2.1图像复原域图像增强的异同
	相同点：改进输入图像的视觉质量
	不同点：图像增强目的是取得较好的视觉效果（即不考虑退换原因）；图像恢复根据相应的退化模型和知识重建或恢复原始的图像（即考虑退化原因）。图像退化指的是有场景得到的图像没能完全反应场景的真是内容，产生了失真等问题。主要问题包括：透镜相差/色差、聚焦不准、模糊、噪声、抖动等问题
## 2.2逆滤波复原算法
## 2.2.1逆滤波复原算法原理		
由退化函数H退化的图像复原的最简单的方法是直接做逆滤波。假设图像退化前的傅里叶变换F(u,v)，退化后的傅里叶变化为G(u,v)，系统函数即退化处理函数的傅里叶变换H(u,v)。
所谓逆滤波复原算法，也就是用退化函数退化图像的傅里叶变换，得到退化前图像的傅里叶变换的估计，F ̂(x,y)为F(u,v)的估计，则F ̂(x,y)=(G(u,v))/(H(u,v))，同时G(u,v)=H(u,v)F(u,v)+N(u,v)，其中N(u,v)为噪声的傅里叶变换。因此，可得F ̂(x,y)=F(u,v)+(N(u,v))/(H(u,v))，由此可知，即使知道退化函数，也不能准确的复原图像，因为N(u,v)位置，甚至有更糟的情况是如果退化函数是零或者是非常小的值，则N(u,v)/H(u,v)的值比较大，那么就很容易支配F(u,v)的估计值。为了解决这个问题，限制滤波的频率，从频谱图可知，高频分量的值接近0，而H(0,0)在频率域中通常是H(u,v)的最高值，因此可缩短滤波半径，使通过的频率接近原点，减少遇到零值的概率。
### 2.2.1逆滤波复原算法实现	
使用MATLAB直接实现。
	image_o=imread('C:\Program Files\MATLAB\R2013a\bin\work\图像复原\lena.bmp');  
	subplot(1,3,1);  
	imshow(image_o);  
	title('原图像');  
	%频率域退化图像，退化函数H(u,v)=exp(-0.0025*( (u-M/2).^2+(v-N/2).^2).^(5/6) )  
	%傅里叶变换  
	f=im2double(image_o);  
	F=fft2(f);  
	F=fftshift(F);  
	%执行退化  
	[M,N]=size(F);  
	[u,v]=meshgrid(1:M,1:N);%生成二维坐标系  
	H=exp(-0.0025* ( (u-M/2).^2+(v-N/2).^2).^(5/6) );  
	F=F.*H;  
	%傅里叶反变换  
	X=ifftshift(F);  
	x=ifft2(X);  
	x=uint8(abs(x)*256);  
	subplot(1,3,2);  
	imshow(x);  
	%  
	title('退化图像');  
	   
	image_d=imread('C:\Program Files\MATLAB\R2013a\bin\work\图像复原\lena_deterioration.bmp');  
	%直接逆滤波图像复原  
	   
	ff=im2double(image_d);%将图像灰度值归一化到0-1之间  
	   
	% 傅里叶变换  
	f_Id=fft2(ff);  
	f_Id=fftshift(f_Id);  
	fH_Id=f_Id;  
	[M,N]=size(fH_Id);  
	% 逆滤波  
	threshold=78;  
	if threshold>M/2  
	        %全滤波  
	        fH_Id=fH_Id./(H+eps);  
	else  
	        %对一定半径范围内进行滤波  
	        for i=1:M  
	            for j=1:N  
	                if sqrt((i-M/2).^2+(j-N/2).^2)<threshold  
	                    fH_Id(i,j)=fH_Id(i,j)./(H(i,j)+eps);  
	                end  
	            end  
	        end  
	end  
	   
	% 执行傅立叶逆变换  
	fH_Id1=ifftshift(fH_Id);  
	f_new=ifft2(fH_Id1);  
	f_new=uint8(abs(f_new)*255);  
	subplot(1,3,3);  
	imshow(f_new);  
	title('滤波半径=78的逆滤波复原图像');  
## 2.3维纳滤波
### 2.3.1维纳滤波算法原理
	维纳滤波也称为最小均方误差滤波，它能够处理被退化函数退化和噪声污染的图像。该滤波方法建立在图像和噪声都是随机变量的基础上，目标是找到为污染图像f(x,y)的一个估计f ̂，使它们之间的均方误差最小，即e^2=E{(f-f ̂ )^2 }，其中E{.}是参数期望值。在假设噪声和图像不相关，其中一个或另一个有零均值，且估计中的灰度级是退化图像中灰度级的线性函数的条件下，均方误差函数的最小值在频率域可以由如下表达式所给出：
F ̂(u,v)=[(H*(u,v) S_f (u,v))/(S_f (u,v) |H(u,v)|^2+S_η (u,v) )]G(u,v)=[(H*(u,v))/(|H(u,v)|^2+(S_η (u,v))⁄(S_f (u,v) ))]G(u,v)=[1/H(u,v)   |H(u,v)|^2/(|H(u,v)|^2+(S_η (u,v))⁄(S_f (u,v) ))]G(u,v)
其中，H(u,v)为退化函数，H*(u,v)为H(u,v)的复共轭，|H(u,v)|^2= H(u,v)H*(u,v)，S_η (u,v)=|N(u,v)|^2为噪声功率谱，S_f (u,v)=|F(u,v)|^2为未退化图像的功率谱，H(u,v)是退化函数的傅里叶变换，G(u,v)是退化后图像的傅里叶变换。
	由上述公式可以发现，如果没有噪声，即S_η (u,v)=0，此时为纳滤波则变为直接逆滤波，如果有噪声，那么S_η (u,v)如何进行估计也是我们应该概率的问题。在实际应用中假设退化函数已知，如果噪声为高斯白噪声，则S_η (u,v)为常数，但是S_f (u,v)通常难以估计。一种近似的解决办法就是使用系数K代替S_η (u,v)/S_f (u,v),因此上面的公式变为如下公式：
F ̂(u,v)=[1/H(u,v)   |H(u,v)|^2/(|H(u,v)|^2+K)]G(u,v)
其中的K值根据实际情况进行选取。
###2.3.2维纳滤波算法实现
	直接使用MATLAB进行实现：
	image_o=imread('C:\Program Files\MATLAB\R2013a\bin\work\图像复原\lena.bmp');  
	subplot(2,2,1);  
	imshow(image_o);  
	title('原图像');  
	%频率域退化图像，退化函数H(u,v)=exp(-0.0025*( (u-M/2).^2+(v-N/2).^2).^(5/6) )  
	%傅里叶变换  
	f=im2double(image_o);  
	F=fft2(f);  
	F=fftshift(F);  
	%执行退化  
	[M,N]=size(F);  
	[u,v]=meshgrid(1:M,1:N);%生成二维坐标系  
	H=exp(-0.0025* ( (u-M/2).^2+(v-N/2).^2).^(5/6) );  
	F=F.*H;  
	%添加高斯噪声  
	%傅里叶反变换  
	X=ifftshift(F);  
	x=ifft2(X);  
	x=uint8(abs(x)*256);  
	x1=imnoise(x,'gaussian',0,0.005);%添加高斯噪声  
	subplot(2,2,2);  
	imshow(x1);  
	%  
	title('退化图像');  
	   
	%  
	Id=im2double(x1);  
	% 傅里叶变换  
	f_Id=fft2(Id);  
	f_Id=fftshift(f_Id);  
	fH_Id=f_Id;  
	D=abs(H);  
	D=D.^2;  
	   
	[M1,N1]=size(fH_Id);  
	% 逆滤波  
	threshold=48;  
	K=0.08;  
	if threshold>M1/2  
	    % 全滤波  
	    fH_Id=fH_Id./(H+eps);  
	else  
	    %对一定半径范围内进行滤波  
	    for i=1:M1  
	        for j=1:N1  
	            if sqrt((i-M1/2).^2+(j-N1/2).^2)<threshold  
	                % 维纳滤波公式  
	                fH_Id(i,j)=fH_Id(i,j)./(H(i,j)) .* (D(i,j)./(D(i,j)+K));  
	            end  
	        end  
	    end  
	end  
	% 执行傅立叶逆变换  
	fH_Id1=ifftshift(fH_Id);  
	f_new=ifft2(fH_Id1);  
	f_new=uint8(abs(f_new)*255);  
	subplot(2,2,3);  
	imshow(f_new);  
	title('维纳滤波复原图像');  
	   
	fH_Id2=f_Id;  
	[M2,N2]=size(fH_Id2);  
	if threshold>M2/2  
	        %全滤波  
	        fH_Id2=fH_Id2./(H+eps);  
	else  
	        %对一定半径范围内进行滤波  
	        for i=1:M2  
	            for j=1:N2  
	                if sqrt((i-M2/2).^2+(j-N2/2).^2)<threshold  
	                    fH_Id2(i,j)=fH_Id2(i,j)./(H(i,j)+eps);  
	                end  
	            end  
	        end  
	end  
	   
	fH_Id3=ifftshift(fH_Id2);  
	f_new3=ifft2(fH_Id3);  
	f_new3=uint8(abs(f_new3)*255);  
	subplot(2,2,4);  
	imshow(f_new3);  
	title('直接逆滤波复原图像');  

## 2.4约束最小二乘方滤波
### 2.4.1约束最小二乘方滤波算法原理
	在图像复原中，约束最小二乘方滤波是图像复原技术中较为重要的一种方法。维纳滤波要求未被退化图像和噪声的功率谱必须是已知的，通常这两个功率很难估计，尽管用一个常数去估计功率谱比，然后并不总是一个适合的解。约束最小二乘方滤波要求噪声的方差和均值，这些参数可以通过给定的退化图像计算出来。这个是约束最小二乘方滤波算法相比维纳滤波的一个重要的优点。
  约束最小二乘方滤波的核心是解决退化函数H(u,v)对噪声的敏感性问题，而减少噪声敏感性问题的一种方法是以平滑度量的最佳复原为基础的，如图像的二阶导数即拉普拉斯变换，于是，找到一个带约束条件的最小准则函数C，定义如下：
C=∑_(x=0)^(M-1)▒∑_(y=0)^(N-1)▒[∇^2 f(x,y)]^2 
	约束条件为：
|(|g-Hf ̂ |)|^2=|(|η|)|^2
	其中，f ̂是未退化图像的估计，∇^2是拉普拉斯算子，求函数C的最小值，便得到最好的平滑效果即最佳复原。使用拉格朗日乘数法，在频域中，函数C可表示为C=|(|PF ̂ |)|_2^2，其中P是拉普拉斯算子的傅里叶变换，则频率域中，拉格朗日函数为：
L(F ̂,λ)=‖PF ̂ ‖_2^2+λ(‖G-HF ̂ ‖_2^2-‖N‖_2^2)
其中，γ=1⁄λ,H*为H的复共轭
F ̂=(H*)/(|H|_2^2+γ‖P‖_2^2 )∙G(u,v)
### 2.4.1约束最小二乘方滤波算法实现
MATLAB实现
	close all;  
	clear all;  
	clc;  
	I = im2double(imread('C:\Program Files\MATLAB\R2013a\bin\work\图像复原\lena.bmp'));  
	[hei,wid,~] = size(I);  
	subplot(2,2,1),imshow(I);  
	title('原图像');  
	% 模拟运动模糊.  
	LEN = 21;  
	THETA = 11;  
	PSF = fspecial('motion', LEN, THETA);%产生运动模糊算子，即点扩展函数  
	blurred = imfilter(I, PSF, 'conv', 'circular');  
	subplot(2,2,2), imshow(blurred); title('模糊图像');  
	Pf = psf2otf(PSF,[hei,wid]);%退化函数的FFT  
	% 添加加性噪声  
	noise_mean = 0;  
	noise_var = 0.00001;  
	blurred_noisy = imnoise(blurred, 'gaussian',noise_mean, noise_var);  
	subplot(2,2,3), imshow(blurred_noisy)  
	title('带运动模糊和噪声图像')  
	p = [0 -1 0;-1 4 -1;0 -1 0];%拉普拉斯模板  
	P = psf2otf(p,[hei,wid]);  
	gama = 0.001;  
	If = fft2(blurred_noisy);  
	numerator = conj(Pf);%conj函数，用于求一个复数的复共轭  
	denominator = Pf.^2 + gama*(P.^2);  
	deblurred2 = ifft2( numerator.*If./ denominator );%约束最小二乘方滤波在频率域中的表达式  
	subplot(2,2,4), imshow(deblurred2)  
	title('约束最小二乘方滤波后图像'); 

## 2.5超分辨率图像重建
### 2.5.1基于插值的图像超分辨率算法
	此算法是重构算法中最容易、计算量最少的一类算法。图像的插值的基本思路是根据已经知道的周围相邻的像素点上的灰度值来求不知道的像素点上的灰度值，这样就会使图像的信息增多，从而能得到比原始图像在每单位面积上的像素高很多的HR图像。经典的插值方法有最近邻插值、双线性插值、双三次插值以及样条插值。
（１）最近邻插值。根据字面意思就可Ｗ知道该插值法是根据最近的像素点上的灰度值来得到不知道的像素点上的灰度值。它又叫做零阶插值，可兑是最单一而且是最方便实现的基于插值的算法。
此方法的优势是计算很容易而且计算速率很快。不足之处是得到的图像不是很理想，而且非常易于在边缘处呈现银齿现象和马赛克现象。
（２）双线性插值。此方法的“双”是在方向上考虑两个，也就是说它是在竖直方向上和与此成９０度的方向上依次进行线性插值的一种插值方法。
此方法的优势是能平滑图像边缘，能很好地解决由最近邻插值所引起的图像边缘银齿效应及块效应的问题。不足之处是会使图像在高频上一部分的信息减退，进而会造成图像不清晰，这样会大大影响人们的视觉成效。
（３）双Ｈ次插值。此方法中需要所求的插值点是根据这个点附近上下左右4个依此点为中屯、的开区间上实行Ｈ次插值得到的，也就是说附近一共有1６个点。

此方法优势是能够更好地解决由最近邻插值所引起的图像边缘错齿效应和块效应问题，而且插值后获得的图像质量很显然比前两种的好。此方法与前两插值法相比，很明显的不足之处是运算量比较大些而且运行时间比较长。
（４）样条插值。样条插值不同于上面３种插值，上面３种插值是由若干个
单项式的和组成的代数式插值。这个代数式插值由所有点决定，要是有其中一点改变，那么整个代数式都会变。样条插值比由若干个单项式的和组成的代数式值结果好，其中样条插值中的很少的阶数就能达到由若干个单项式的和构成的代数式插值多阶的效果。
此方法的优势是可以解决由若干个单项式的和组成的代数式插值在数据点间出现的震荡现象。不足之处是计算量大。
### 2.5.2基于重建的图像超分辨率算法
#### 2.5.2.1基于重建的图像超分辨率算法原理
现在基于重建的图像超分辨率算法目前比较主流的算法是以下几种：
（1）、凸集投影算法（POCS）
	此方法是计算机进行断层扫描中比较早使用的，是从一维到二维扩展的算法。通常使用在数据有限的情况下恢复丢失的信息。在集合理论方法中，SR图像的解集合空间需要与一些约束集相交，目的是用来产生比此前的解集合空间还小的解集合空间。约束集表示期望SR图像特征，（e.g.积极性、有界能量性、对数据的保真度以及平滑性等）POCS是一个迭代过程，它主要思想是给出SR图像空间中随意的一个点，找到一个满足所有凸约束条件的点，最终获得HR图像的一个估计。
	将HR图像z的解集合空间的约束定义在z空间上的凸集。一般用集合{z│|Y-Hz|<σ_0 }来表示。集合{z│z_i>0,任意i}表示积极性，{z│‖z‖≤E}表示能量有界性。对于这样定义的凸约束集合C_i (i=1,2,3,…,m)，将z空间上随意一个点投影到凸集C_i上，此时可以很容易确定出投影算子P_i。综上所诉，我们能够轻易求得和HR图像z距离最近的一点g∈C_i,POCS方法的每一步迭代过程可以表示为：
z^(n+1)=P_m P_(m-1)…P_1 z^n
	重复运用上式将求出收敛到m个凸约束集的交集的解。注意，这一点通常是非唯一的，并且取决于初始猜测。POCS重建方法已经成功应用于复杂退化模型。
（2）、迭代反投影法（IBP）
	此方法是已知一个SR的估计z ̂和成像模型H，然后可以将LR图像Y ̂写成Y ̂=Hz ̂这种形式。迭代反投影是通过经由反投影算子H^BP对第j个模拟LR图像Y ̂^({j})和观察得到的LR图像Y之间的误差进行反投影来更新SR重建的估计。通常H^BP近似于H^(-1)。代数式：
z ̂^((j+1))=z ̂^((j))+H^BP (Y-Y ̂^((j) ) )=z ̂^((j)) H^BP (Y-〖Hz ̂〗^((j) ) )
	首先需要给出一个关于误差的阈值，然后一直重复计算上式，直到误差小于这个值时，迭代就会结束。否则继续迭代直到满足要求为止，最后使得到Y ̂^((j) )最小化。

### 2.5.3基于学习的图像超分辨率算法
	此算法是比较流行的SR技术，与传统方法相比，基于学习的SR算法能获得较好的效果，它是建立在人工智能技术的基础上做的，基本思路是：首先需要知道相关训练图集；其次确定出测试样本与训练图像集之间的领域关系；最后再给出最有权值约束。简而言之，就是通过先验知识来推断需要得到的HR图像，得到的结果是测试样本HR图像接近的。由此方法在LR图像中所包含的信息不能满足HR图像需求的情况下可以得到非常多的高层方面的信息，因此，此算法在图像应用中可以取得相当满意的成果。此算法的核心是得出HR图像和LR图像之间的系统模型，可以用插值核、查找表和映射系数等来表示这一模型。基于样例方法、领域嵌入方法、稀疏表示方法和支持向量回归方法是此领域中常用的模型。
（１）基于样例的方法。此方法是先将图像分成一块一块的，然后再把测验图像区分成子域，最后经过一些处理可Ｗ得出ＨＲ图像块中的移动矩阵，而且也可Ｗ得到ＨＲ图像块和ＬＲ图像块之间的移动矩阵。在Ｓ民中，该方法是最早提出来的基于学习的方法，此方法的优势是可Ｗ得出很不错的高频方面的信息。但是很明显的不足之处是就对训练样本要求高、对噪声敏感度比较强。
（２）邻域嵌入方法口。此方法是在基于特征的空间中，在假设ＨＲ图像块与之相对应的ＬＲ图像块之间进行的，假设它们之间能形成相同的流形，该些流行是关于局部几何结构的。该方法的具体步骤是：首先需要通过训练得出图像块间的流形，这些流形是ＨＲ图像块与之相对应的ＬＲ图像块之间的；其次两者之间对应关系用邻域表示；然后再得出ＨＲ图像块的估计，此估计是通过结合这些加权系数求出的。
此方法的优势是噪声敏感度不强并且不需要太多的训练样本，不足之处是由于邻域的限制缩小了其适用范围。
（３）稀疏表示法。此方法首先需要一个过完备的词典，此词典是先在Ｈ艮图像中随意选取一部分图像块组成；其次是需要求出所选取的任意一个图像块在这个词典下的稀疏表示；最后重构出ＨＲ图像。
此方法的优势是解决了邻域嵌入方法中选取邻域大小的问题。不足之处是由于过完备词典的限制，只能在某些领域上实现超分辨率。此方法不适用于一些通用图像的超分辨率。
（４）支持向量回归方法口。此方法是凸二次规划问题，也就是说把半正定规划问题转换成二次规划问题求最优解。其中转换是通过加入一些约束条件转换的。例如，对于测试数据来说，首先进行分类；其次是在对应的类中进行支持向量回归；最终得出ＨＲ图像。
该方法的应用口范围特别广，可Ｗ应用在模式识别、概率密度估计、回归估计等领域中。此方法的优势是不用对样本进行手动选取，它可自动选取。此 外还不对训练集作要求，有很少的训练集。当然也存有不足之处，比如说在对图像进行恢复时的对比度不足。
# 三、对象识别
## 3.1神经网络图像识别
### 3.1.1神经网络图像识别算法原理（CNN）
	图像分类可以认为是给定一副测试图片作为输入，输出该图片是属于哪一类。参数W是图像的宽度，H是高度，C是通道的个数；彩色图像中C=3，灰度图像中C=1,。一般的会设定总共类别的个数。卷积神经网络则可以看着这样的黑匣子。输入时原始图片I，输出是L维的向量。L表示预先设定的类别个数。向量v的每一个维度代表图像属于对应类别的可能性的大小。如果是但类别识别问题，也就是说每一幅图像只分配L个标签，那么可以对v中的元素进行比较，取决最大的值对应的标签作为分类的结果。V可以使一个概率分布的形式，即每一个元素，并且其中表示v的第i个元素。也可以是从负无穷大到正无穷大的实数，越大代表属于对应类别的可能性越大。在卷积神经网络的内部，是由很多的层构成，每一个层可以认为是一个函数，输入时信号x，输出是信号y，输出的y又可以作为其他层的输入。CNN的前段，中段，末段的定义如下所述。
1. 网络的前段（数据预处理）。前段指的是对图像数据处理，可以称为是数据层。数据层的处理需要一下两个步骤：数据裁减以及排除颜色干扰。
数据裁减：输入图像的大小可能是各不相同的，有一些图像的分辨率较大，有一些则比较少，而且长宽也会不一定会一样。对于这种不一致性，理论上可以不予处理，但是这要求网络中其他的层次支持这样的输入。目前大部分情况下采用的是通过数据裁剪的方法使得输出的图像使固定分辨率。在网络训练的阶段，裁剪的位置从原始的图像上随机选择，只需要满足裁剪好的子图完全落在图像中即可，通过随机的方式，是因为相当于增加了额外数据，所以能够缓解过拟合的问题。
颜色干扰：裁剪之后的原图，每一个像素的是0到255的固定数值。进一步的处理，包括减去均值，以及等比例缩放像素值是的像素值的分布基本在[-1,1]之间。除了这些常规操作之外，也会对图像进行归一化，相当于对图像进行增强。
2. 网络中段（CNN网络各个层的设置）。	主要介绍卷积神经网络中常用的层的定义，即输入的数据x是什么维度，输出y是什么维度以及如何从输入得到输出。
	卷积层基本组成如下所示：
 
输入层→卷积→池化→全连接→全连接→输入结果
架构简介：
卷积神经网络利用输入由图像组成的试试，并以更合理的方式约束架构，特别与常规的神经网络不同的,CNN的各层具有三维排列的神经元：宽度、高度、深度（深度指的是激活体积的第三位，而不是完整神经网络的深度，它可以指的是网络中的总层数）。也就是一层中的神经元只会在他之前连接到层的一个小区域，而不是以完全连接的方式连接到所有神经元。CNN在三个维度中排列其神经元，如在其中一个层中可视化，CNN的每一层都将3D输入体积转换为神经元激活的3D输出体积。CNN由图层组成，每个图层都有一个简单的API，它将输入的3D体积转换为输出的3D体积，具有一些可能有或可能没有参数的可微分函数。	
用于构建CNN的图层
简单的CNN是一系列层，CNN的每一个层都通过可微函数将一个激活体积转换为另一个激活体积。CNN主要由三种类型的层来组成：卷积层、池化层和完全连接层。我们将堆叠这些层形成CNN架构。
下面将通过讲解最常用的一种类型来介绍CNN算法：（CNN for CIFAR-10）
	INPUT：[32x32x3]将保持图像的原始像素值，图像的像素宽度为32，像素高度为32，并且具有三种颜色通道R,G,B。
	CONV层：计算连接到输入中局部区域的神经元的输出，每个神经元计算它们的权重与他们在输入体积中连接的小区域之间的点积。这里根据经验选择12个过滤器，这里可能会导致诸如[32x32x12]的音量。
	RELU层将应用元素激活函数，例如max(0，x)的值为0.这使得体积的大小保持不变（仍然为[32x32x12]）
	POOL层：将沿空间维度（宽度、高度）执行下采样操作，从而产生诸如[16x16x12]的音量。
	FC层（完全连接层）：将计算类别的得分，导致大小的体积[1x1x10],其中10个数字中的每一个对应于类别得分，例如10个 类别的CIFAR-10.与普通的神经网络一样，顾名思义，该层中的每个神经元都将连接到前一卷中的所有数字。
通过上述方式，CNN将原始图像逐层从原始像素值转换为最终的类得分。值得注意的是，某些图层包含参数而其他图层不包含。CONV/FC层执行的变换不仅是输入体积中的激活的函数，而且还有参数（神经元的权重和偏差）的函数。另一方面，RELU/POOL层将实现固定功能。CONV/FC层中的参数将使用梯度下降进行训练，以便ConvNet计算的类得分与每个图像的训练集中的标签一致。

综上所述：
	CNN架构在最简单的情况下是一个图层列表，它将图像卷转换为输出卷（保持类得分）
	有几种不同类型的图层（CONV-FC-RELU-POOL是目前最受欢迎的）
	每个图层都接受输入3D体积，并通过可微分函数将其转换为输出3D体积
	每个层可能有也可能没有参数（CONV-FC有参数，RELU/POOL无参数）
	每个层可能有也可能没有额外的超参数（CONV-FC-POOL有，RELU无）
实现效果如下所示：
 
参考链接：(https://cs231n.github.io/convolutional-networks/#conv)
3. 网络末段：从网络训练的角度，末段主要是损失函数。也就是将数据射为一个标量，通过随机梯度下降的方式，使得损失函数逐渐的降低。目前使用比较广泛的Softmax回归和Hinge损失函数。
Softmax回归
在使用广义线性模型模拟这个多项式分布模型之前，需要先推导一个函数，这个函数在广义线性模型的目标函数中会用到，这个函数就是Softmax函数。表达式如下所示：
η_i=log ϕ_i/ϕ_k 

将上述表达式转换为η_i与ϕ_i的表达式，如下所示：
ϕ_i=e^(η_i )/(∑_(j=1)^k▒e^(η_j ) )
根据广义线性模型的假设：
η_i=θ_i^T x  (i=1,2,…,k-1)
Θ是模型中的参数，为了符号上的方便我们将定义θ_k=0,所以
η_k=θ_k^T x=0
所以模型在给定x的条件下y的分布
p(y=i│x;θ)=ϕ_i=e^(θ_i^T x)/(∑_(j=1)^k▒e^(θ_j^T x) )
上面的表达式求解的是y=i时的概率，在softmax回归这个广义线性模型中，目标函数是：
h_θ (x)=E[T(y)│x;θ]=[■((exp⁡(θ_1^T x))/(∑_(j=1)^k▒〖exp⁡(θ_j^T x)〗)@■((exp⁡(θ_2^T x))/(∑_(j=1)^k▒〖exp⁡(θ_j^T x)〗)@■(⋮@(exp⁡(θ_(k-1)^T x))/(∑_(j=1)^k▒〖exp⁡(θ_j^T x)〗))))]
通过参数拟合，得到最大化似然函数来求解最优的参数θ，可以使用梯度上升或者牛顿方法，求解最优的参数θ，就可以使用目标函数h_θ (x)进行分类，使用h_θ (x)进行多分类的方式就叫做Softmax回归。

在图像处理中，输入时，表示输入图像在各个类别中的可能性；同时需要输入图像的标签k，输出的是损失值。首先将输入归一化到[0,1]之间，通过softmax函数，然后通过交叉熵定义损失值，也就是：该损失函数主要应用于单类别分类问题中。
从数学上来看，非线性的sigmod函数对中央区的信号增益较大，对两侧区的信号增益小，在信号的特征空间映射上，有很好的效果。从神经科学上来看，中央区和神经元的兴奋状态相像，两侧区和神经元的抑制状态相像，因而在神经网络学习中，可以重点特征推向中央区，将非重点特征推向两侧区域。
###3.1.2神经网络图像识别算法算法实现（CNN）
	（1）数据集读取，对数据进行预先定义
	#读取MNIST数据集  
	from tensorflow.examples.tutorials.mnist import input_data  
	mnist = input_data.read_data_sets('MNIST_data',one_hot=True)  
	#预先定义输入值x，输出真实值y，placeholder为占位符  
	x = tf.placeholder(tf.float32,shape=[None,784])  
	y_ = tf.placeholder(tf.float32,shape =[None,10])  
	#keep_prob是改变参与计算的神经元个数的值  
	keep_prob = tf.placeholder(tf.float32)  
	x_image = tf.reshapr(x,[-1,28,28,1])  
本次练习使用的是Google的经典的图像识别的数据集，图片的大小是28*28，下载链接是：https://pan.baidu.com/s/1d9ty82 密码：jcam
X、Y_现在只是使用占位符表示，传入具体的值之后，就可以直接代入进行计算
Shape=[None,784]是数据维度大小——由于每一张图片的大小都是28*28的，计算的时候讲二维数据转换成一个一维的长度为784的新向量，None表示值大小不一定，现在指的是x，y_的数量暂时不定
Keep_prob是改变参与计算的神经元个数的值
	（2）权重、偏置值函数
	##权重和偏置函数的计算  
	#产生随机变量  
	def weight_variable(shape):  
	    initial = tf.truncated_normal(shape,stddev=0.1)  
	    return tf.Variable(initial)  
	  
	def bias_variable(shape):  
	    initial = tf.constant(0.1,shape=shape)  
	    return tf.Variable(initial)  
truncated_normal()函数：选取位于正态均值=0.1附近的随机值
（3）卷积函数、池化函数定义
	##卷积函数、池化函数定义  
	def conv2d(x,W):  
	    #strides = [1,水平移动步长，竖直移动步长，1]  
	    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')  
	def max_pool_2x2(x):  
	    #strides = [1,水平移动步长，竖直移动步长，1]  
	    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')  
输入x是图片的信息矩,W是卷积核的值
卷积层conv2d()函数是strides参数要求第一个，最后一个参数必须是1；
第二个参数表示：卷积核每次向右移动的步长
第三个参数表示：卷积核每次向下移动的步长
当我们的卷积步长值越大，得到的输出图像的规格就会越小，为了是得到的图像的规格和原图像保持一样的大，在输入图像四周填充足够多的0的边界就可以解决这个问题，这是padding的参数就为“SAME”。
Padding的另一个可选的参数为“VALID”，区别于“SAME”的是：不用0来填充边界，这时得到的图像的规格会小于原图像。新图像尺寸大小 = 原数据尺寸大小-卷积核尺寸大小+1，所以padding选用“SAME”。
池化函数用简单传统大小模板做max pooling，池化步长为2，选过的区域下次不再选取
4. 第一次卷积+池化
	##第一次卷积+池化  
	x_image = tf.reshape(x,[-1,28,28,1])  
	#卷积层1网络结构定义  
	#卷积核1：patch=5x5;in size 1;out size 32;激活函数RELU非线性处理  
	W_conv1 = weight_variable([5,5,1,32])  
	b_conv1 = bias_variable([32])  
	#output size 28*28*32  
	h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1)+b_conv1)  
	#output size 14*14*32  
	h_pool1 = max_pool_2x2(h_conv1)  
图片集是黑白单色，x_image中的图片尺寸从参数最后一个是1，彩色的是3
第一次选取的卷积核大小是5*5的，输入的通道数是1，输出的通道是32
卷积核的值这里就相当于权重值，用随机数列生成的方式得到
由于MNIST数据集图片大小都是28*28，且是黑白单色，所以准确的图片尺寸大小是28*28*1(1表示图片只有一个色层，彩色图片则为3个色层--RGB)，所以经过第一次卷积后，输出的通道数由1变成了32，图片尺寸变为:28*28*32,再次进过第一次池化（池化步长是2），图片尺寸为14*14*32
5. 第二次卷积+池化
	##第二次卷积+池化  
	#卷积层1网络结构定义  
	#卷积核1：patch=5x5;in size 32;out size 64;激活函数RELU非线性处理  
	W_conv2 = weight_variable([5,5,32,64])  
	b_conv2 = bias_variable([64])  
	#output size 14*14*64  
	h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)  
	#output size 7*7*64  
	h_pool2 = max_pool_2x2(h_conv2)  
第二次卷积大小是5*5的，第二次输入的通道数是32，输出的通道数是64
第一次卷积+池化输出的图片大小是14*14*32,经过第二次卷积后图片尺寸变为14*14*64，再次进过第二次池化（池化步长是2），最后输出的图片的尺寸7*7*64
6. 全连接层1、全连接层2
	##第二次卷积+池化  
	#卷积层1网络结构定义  
	#卷积核1：patch=5x5;in size 32;out size 64;激活函数RELU非线性处理  
	W_conv2 = weight_variable([5,5,32,64])  
	b_conv2 = bias_variable([64])  
	#output size 14*14*64  
	h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2)+b_conv2)  
	#output size 7*7*64  
	h_pool2 = max_pool_2x2(h_conv2)  
	  
	##全连接层1、全连接层2  
	#全连接层1  
	W_fc1 = weight_variable([7*7*64,1024])  
	b_fc1 = bias_variable([1024])  
	h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])  
	h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)  
	h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)  
	#全连接层2  
	W_fc2 = weight_variable([1024,10])  
	b_fc2 = bias_variable([10])  
	prediction = tf.matmul(h_fc1_drop,W_fc2)+b_fc2  
全连接层的输入就是第二次池化后的输出，尺寸是7*7*64，全连接层1有1024个神经元tf.reshape（a,newshape）函数，当newshape=-1时，函数根据已有的维度计算出数组的另外shape属性值，keep_prob是减小过拟合现象，每次只让部分神经元参与工作，使得权重得到调整，只有当keep_prob=1时，才是所有的神经元都参与工作。全连接层2有10个神经元，相当于生成的分类器，全连接层1,2，得到的预测值存入prediction中。
7. 梯度下降法优化，求准确率
	##梯度下降法优化，求准确率  
	#二次代价函数：预测值与真实值的误差  
	loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=prediction))  
	#梯度下降，选用AdamOptimizer优化器  
	train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)  
	#结果存放在一个布尔型列表中  
	correct_prediction =tf.equal(tf.argmax(prediction,1),tf.argmax(y_,1))  
	#求准确率  
	accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))  
由于数据集太庞大，采用优化器是AdamOptimizer，学习率是1e-4,tf.argmax(prediction,1)返回的是对于任一输入x预测到的标签值，tf.argmax(y_,1)代表正确的标签纸，correct_prediction这里是返回一个布尔数组。为了计算我们分类的准确率，将布尔值转换为浮点数来代表对与错，然后取平均值。
8. 保存模型与参数
	##保存参数  
	for i in range(000):  
	    batch = mnist.train.next_batch(50)  
	    if i % 100 == 0：  
	    train_accuracy = accuracy.eval(feed_dict = {x:batch[0],y_:batch[1],keep_prob:1.0})  
	    print('step',i,'training accuracy',train_accuracy)  
	    train_step.run(feed_dict ={x:batch[0],y_:batch[1],keep_prob:0.5})  
	saver.save(sess,'./model.ckpt')  
	print('test accuracy %g'%accuracy.eval(feed_dict={x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0})) 

## 3.2基于小波矩的图像识别
将输入二维二值图像的不变矩阵作为识别特征，运用BP网络进行识别，将输入图像经过归一化处理，极坐标化，旋转不变小波矩特诊提取后，送入BP网络分类器中进行识别，获得识别结果。
基于小波矩的图像识别方法的特点如下：
（1）小波矩特征对具有平移、缩放和旋转的样本具有良好的分辨能力，在未加噪声的情况下，小波矩特征都能正确分辨测试样本，识别率优于几何矩，差距达到30个百分点
（2）随着添加随机噪声，两种矩特征的识别率都有所下降，但是由于小波矩具有较好的提取图像局部特征能力，所以小波矩的识别率下降相对缓慢，最高正确识别率达到98%
（3）小波矩特征较为稳定。几何矩的粪便能力有时不能随着特征数的增加而稳定，这样需要较多的分辨特征的情况下是不利的。而小波矩虽然有一定波动，但波动幅度有限，其判别精度整体为稳定增加趋势
##3.3基于分形特征的红外图像识别
一般认为:自然纹理图像满足分形特性，可以提取其分形特征以供进一步的纹理分割、目标识别等，而人造目标图像是不满足分形特性的，不可以提取其分形特征。基于分形特征的红外图像识别方法步骤如下:
(1)红外图像预处理
由于探测器本身固有的特性，红外热图像普遍存在目标与背景对比度较差，图像边缘模糊，噪声较大等缺点，因此必须进行预处理，以增强其对比度。
(2)红外图像分形特征提取
分别提取提取基于分形维数的特征、基于Hurst指数的分形特征、基于缝隙(lacunarity)的分形特征。
(3)基于神经网络的红外图像识别
人工神经网络是进行目标识别(包括图像识别)的强有力工具。它通过对原始数据的训练，获得最佳的权系数，取得很好的识别结果 。

